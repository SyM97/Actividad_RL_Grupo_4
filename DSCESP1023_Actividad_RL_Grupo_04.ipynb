{"cells":[{"cell_type":"markdown","metadata":{"id":"3qMnOMrtnwtE"},"source":["# Módulo Deep Learning\n","## Actividad 2: Reinforcement Learning: **Frozen lake problem**"]},{"cell_type":"markdown","metadata":{"id":"J4d_Yp6jeevx"},"source":["-Simeon Milenov Mitev\n","\n","-Daniel Gonzalez Valera\n","\n","-Cristopher Pazmiño\n"]},{"cell_type":"markdown","metadata":{"id":"_ypTIoCpeiSW"},"source":["# Actividad Reinforcemente Learning\n","\n","Resolver el problema del Frozen lake de OpenAI Gym. Documentación: https://www.gymlibrary.dev/environments/toy_text/frozen_lake/\n","\n","## Objetivos\n","- Conseguir movermos aleatoriamente hasta cumplir el objetivo\n","- Conseguir que el agente aprenda con Q-learning\n","- (Opcional) Probar con otros hiperparámetros\n","- (Opcional) Modificar la recompensa\n","\n","## Consideraciones\n","- No hay penalizaciones\n","- Si el agente cae en un \"hole\", entonces done = True y se queda atascado sin poder salir (al igual que ocurre cuando llega al \"goal\")\n","\n","## Normas a seguir\n","\n","- Se debe entregar un **ÚNICO GOOGLE COLAB notebook** (archivo .ipynb) que incluya las instrucciones presentes y su **EJECUCIÓN!!!**.\n","- Poner el nombre del grupo en el nombre del archivo y el nombre de todos los integrantes del grupo al inicio del notebook.\n","\n","## Criterio de evaluación\n","\n","- Seguimiento de las normas establecidas en la actividad.\n","- Corrección en el uso de algoritmos, modelos y formas idiomáticas en Python.\n","- El código debe poder ejecutarse sin modificación alguna en Google Colaboratory."]},{"cell_type":"markdown","metadata":{"id":"9Ly604VTn1ue"},"source":["## **Instalamos librerías**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9516,"status":"ok","timestamp":1713368338872,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"lXbvm0y9No4N","outputId":"63ed8000-91c9-436c-b5bc-f0620aa1cea1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gym==0.17.3 in /usr/local/lib/python3.10/dist-packages (0.17.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.11.4)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.23.5)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (0.18.3)\n","Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n"]}],"source":["!pip install gym==0.17.3\n","!pip install numpy==1.23.5"]},{"cell_type":"markdown","metadata":{"id":"NQreB5h1PER_"},"source":["# Definimos las Librerías"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1713368624846,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"-aiKby2RNy-T"},"outputs":[],"source":["import gym\n","import numpy as np\n","from time import sleep\n","from IPython.display import clear_output\n","import random as rd"]},{"cell_type":"markdown","metadata":{"id":"shd3NqyQn9IO"},"source":["##**Definición del entorno**"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713368626110,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"1_3z3ZByoAcO"},"outputs":[],"source":["# Definimos el entorno\n","env = gym.make('FrozenLake-v0', desc=None, map_name=\"4x4\", is_slippery=False)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713368627011,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"E_Nw22y00NEH"},"outputs":[],"source":["# Fijamos una semilla\n","seed_value = 42\n","env.seed(seed_value)\n","np.random.seed(seed_value)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713368627011,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"fETKbHsBOGtB","outputId":"7117969c-eeb8-4731-963e-197f912dee15"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n","None\n"]}],"source":["env.reset() # En este caso, empieza desde la misma posición inicial\n","print(env.render())"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713368628880,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"x0p9Zxwz0UNs","outputId":"6d03d4ad-da3f-4a7d-cda9-86e27b7e97d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Action Space Discrete(4)\n","State Space Discrete(16)\n"]}],"source":["print(\"Action Space {}\".format(env.action_space))\n","print(\"State Space {}\".format(env.observation_space))"]},{"cell_type":"markdown","metadata":{"id":"JarMsz_-0YfL"},"source":["Acciones posibles:\n","* 0: izquierda\n","* 1: abajo\n","* 2: derecha\n","* 3: arriba"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713368629621,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"Xyya51AU0shk","outputId":"bb49fc70-6c93-49d0-b091-529b45aacdb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["State: 0\n"]}],"source":["# Identificador de estado\n","state = env.s\n","print(\"State:\", state)"]},{"cell_type":"markdown","metadata":{"id":"jAHw0ZBm1C1-"},"source":["## **¡Nos movemos aleatoriamente!**"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713368630217,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"itxDrfce3-x0","outputId":"dffe753b-1fef-4c1b-e201-71bddd01b336"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n"]}],"source":["steps = 0\n","env.reset()\n","env.render()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713368631651,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"D5EoVvD61Gjb","outputId":"75affb04-3873-4d17-d34b-400373e75eec"},"outputs":[{"name":"stdout","output_type":"stream","text":["State: 4\n","4 0.0 False {'prob': 1.0}\n","  (Down)\n","SFFF\n","\u001b[41mF\u001b[0mHFH\n","FFFH\n","HFFG\n","Step: 1\n"]}],"source":["# Acciones: 0=izquierda, 1=abajo, 2=derecha, 3=arriba\n","action = 1\n","state, reward, done, info = env.step(action)\n","\n","print(\"State:\", state)\n","print(state, reward, done, info)\n","\n","env.s = state\n","env.render()\n","\n","steps += 1\n","\n","print(f\"Step: {steps}\")"]},{"cell_type":"markdown","metadata":{"id":"1e037a31-5c23-418b-940e-b346b36a5b7c"},"source":["# Movimientos aleatorios hasta la recompensa"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1713368633198,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"AoJB2b1sSU1V"},"outputs":[],"source":["class bcolors:\n","    RED = '\\u001b[31m'\n","    GREEN = '\\u001b[32m'  # Para visualizar mejor los resultados como recompensas negativas o positivas.\n","    RESET = '\\u001b[0m'"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1713368635276,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"pcxOIH3aRkVP"},"outputs":[],"source":["def run_frozen_lake_random_move_simulation():\n","\n","    timestep, penalties, reward = 0, 0, 0\n","    done = False\n","\n","    while reward == 0:\n","        if done is True:  # Definimos esta condición necesaria que se nos pide en el ejercicio.\n","            env.reset()\n","\n","        action = env.action_space.sample() # Se elige una acción aleatoria.\n","        state, reward, done, info = env.step(action)  # Para ejecutar esa acción.\n","\n","        timestep += 1\n","\n","        # Limpia la salida y muestra el entorno después de cada acción.\n","        clear_output(wait=True)\n","        print(\"Estado del juego:\")\n","        env.render(mode='human')\n","        print(\"\")\n","\n","        # Para imprimir los resultados.\n","        if reward < 0:\n","            print(f\"Recompensa actual: {bcolors.RED}{reward}{bcolors.RESET}\")\n","        else:\n","            print(f\"Recompensa actual: {bcolors.GREEN}{reward}{bcolors.RESET}\")\n","        print(\"\")\n","        print('Estado actual', state)\n","        sleep(0.05)  # Tiempo de espera entre cada intento.\n","\n","    # Ver los resultados.\n","    print(\"Pasos totales tomados: {}\".format(timestep))\n","    print(\"Penalizaciones incurridas: {}\".format(penalties)) # Para confirmar de que no hay penalizaciones."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12260,"status":"ok","timestamp":1713368653408,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"OGxBAITYRkSS","outputId":"2c6b7ad7-e701-4586-b349-fec8e1968c62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Estado del juego:\n","  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HFF\u001b[41mG\u001b[0m\n","\n","Recompensa actual: \u001b[32m1.0\u001b[0m\n","\n","Estado actual 15\n","Pasos totales tomados: 237\n","Penalizaciones incurridas: 0\n"]}],"source":["run_frozen_lake_random_move_simulation()"]},{"cell_type":"markdown","metadata":{"id":"8d0f7fec-5ae1-4d19-afb0-1bd515458fed"},"source":["# Q-learning"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1713368665263,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"017a583a-4e2e-4a14-817a-948ed0ab2e66"},"outputs":[],"source":["q_table = np.zeros([env.observation_space.n, env.action_space.n])"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1713368666336,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"e7ed7bdf-468e-4c0a-a61d-094c67b2d5eb","outputId":"9c73b4b9-ebf8-4afe-9087-fb8b8f496c22"},"outputs":[{"data":{"text/plain":["array([0., 0., 0., 0.])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["q_table[14]"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1713368667071,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"c2e75cbf-9080-4a11-9b4d-3491c6d8ca8e"},"outputs":[],"source":["def greedy(epsilon,q_table,state,env):\n","    if rd.random() < epsilon:\n","        action=env.action_space.sample()\n","    else:\n","        action=np.argmax(q_table[state])\n","    return action"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":196393,"status":"ok","timestamp":1713368865023,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"3df97e50-4d8b-4e7d-82a5-4060e5b0486b","outputId":"a291a773-080d-4af1-ada9-cad9d8bccf2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: 10000\n","Training finished.\n","\n"]}],"source":["# Hyperparameters\n","alpha = 0.1 # tasa de aprendizaje\n","gamma = 0.6 # tasa de descuento\n","epsilon = 0.1 # greedy policy\n","\n","# For plotting metrics\n","all_timestep = []\n","all_penalties = []\n","\n","episodes = 10001\n","\n","for i in range(episodes):\n","    state = env.reset()\n","\n","    timestep, penalties, reward = 0, 0, 0\n","    done = False\n","\n","    while reward == 0:\n","\n","        if done is True:\n","            env.reset()\n","\n","        action = greedy(epsilon,q_table,state,env)\n","\n","        next_state, reward, done, info = env.step(action)\n","\n","        old_value = q_table[state, action] # En la Q-table, tomamos el valor Q de la acción elegida para el estado actual.\n","        next_max = np.max(q_table[next_state]) # En la Q-table, tomamos el máximo entre los valores Q para el nuevo estado.\n","\n","        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max) # Actualizamos el valor Q.\n","        q_table[state, action] = new_value\n","\n","        state = next_state\n","        timestep += 1\n","\n","    if i % 100 == 0:\n","        clear_output(wait=True)\n","        print(f\"Episode: {i}\")\n","\n","print(\"Training finished.\\n\")"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1713368883341,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"JhEJJ7Lyqvpl","outputId":"20110345-aab0-4646-f8a9-f919dcd4a96c"},"outputs":[{"data":{"text/plain":["array([0.36, 0.6 , 1.  , 0.36])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["q_table[14]"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":733,"status":"ok","timestamp":1713368886103,"user":{"displayName":"Simeon Milenov Mitev","userId":"02949308348335480156"},"user_tz":-60},"id":"af34b91a-7ed6-4e93-90fd-71111d45f683","outputId":"226b73e3-9a57-4dea-cbba-1518e52698b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HFF\u001b[41mG\u001b[0m\n","\n","Recompensa actual: \u001b[32m1.0\u001b[0m\n","\n","Estado actual 15\n","Timesteps taken: 8\n","Penalties incurred: 0\n"]}],"source":["class bcolors:\n","    RED= '\\u001b[31m'\n","    GREEN= '\\u001b[32m'\n","    RESET= '\\u001b[0m'\n","\n","env.s = 0\n","done = False\n","\n","timestep, penalties, reward = 0, 0, 0\n","total_reward = 0\n","\n","while reward == 0:\n","\n","    if done is True:\n","            env.reset()\n","\n","    action = np.argmax(q_table[state]) # Se aplica lo aprendido.\n","    state, reward, done, info = env.step(action)\n","\n","    timestep += 1\n","    total_reward += reward\n","\n","  # Para imprimir cada paso\n","    clear_output(wait=True)\n","    env.render()\n","    print(\"\")\n","    if reward < 0:\n","        print(f\"Recompensa actual: {bcolors.RED}{reward}{bcolors.RESET}\")\n","    else:\n","        print(f\"Recompensa actual: {bcolors.GREEN}{reward}{bcolors.RESET}\")\n","    print(\"\")\n","    print('Estado actual', state)\n","    sleep(0.05)\n","\n","\n","print(\"Timesteps taken: {}\".format(timestep))\n","print(\"Penalties incurred: {}\".format(penalties))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
